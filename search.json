[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "jetson-examples",
    "section": "",
    "text": "This file will become your README and also the index of your documentation.",
    "crumbs": [
      "jetson-examples"
    ]
  },
  {
    "objectID": "index.html#developer-guide",
    "href": "index.html#developer-guide",
    "title": "jetson-examples",
    "section": "Developer Guide",
    "text": "Developer Guide\nIf you are new to using nbdev here are some useful pointers to get you started.\n\nInstall jetson_examples in Development mode\n# make sure jetson_examples package is installed in development mode\n$ pip install -e .\n\n# make changes under nbs/ directory\n# ...\n\n# compile to have changes apply to jetson_examples\n$ nbdev_prepare",
    "crumbs": [
      "jetson-examples"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "jetson-examples",
    "section": "Usage",
    "text": "Usage\n\nInstallation\nInstall latest from the GitHub repository:\n$ pip install git+https://github.com/ninjalabo/jetson-examples.git\nor from conda\n$ conda install -c ninjalabo jetson_examples\nor from pypi\n$ pip install jetson_examples\n\n\nDocumentation\nDocumentation can be found hosted on this GitHub repository’s pages. Additionally you can find package manager specific guidelines on conda and pypi respectively.",
    "crumbs": [
      "jetson-examples"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "jetson-examples",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2",
    "crumbs": [
      "jetson-examples"
    ]
  },
  {
    "objectID": "fastai.html",
    "href": "fastai.html",
    "title": "ResNet18 with fastai on NVIDIA Jetson",
    "section": "",
    "text": "This guide provides step-by-step instructions for setting up an NVIDIA® Jetson Orin Nano™ Developer Kit for deep learning with PyTorch, torchvision, and fastai. The setup will be performed via a terminal from a host machine connected via USB or serial connection.\n\n\n\nJetPack - 6.2 (also compatible with 6.1)\n\nCUDA - 12.6\n\nPython - 3.10\n\ncuSPARSELt - 0.7.0\n\ntorch - 2.5.0a0+872d972e41 (NVIDIA wheel).\n\ntorchvision - 0.20.0 (built from source)\n\nspacy - 3.7.2\n\nfastai - 2.7.18\n\n\n\n\nIf your Jetson device is controlled via serial connection, here are some instructions to connect to Wifi using nmcli:\n\nCheck available WiFi networks: nmcli device wifi list\n\nConnect to a WiFi network: nmcli device wifi connect \"SSID_NAME\" password \"YOUR_PASSWORD\"\n\nVerify the Connection: nmcli connection show --active\n\nNote: If encountering unauthorized error, add sudo before these commands.\nAfter connecting to WIFI, the user can retrieve the IP address assigned to the Jetson device. Check the active connections with the command in step 3, which should output their names, UUIDs, types, and devices. Notice the device of the WIFI (type) connection and use it with the command ip a show &lt;DEVICE_NAME&gt;. From another device, e.g., host machine, that also connects to this WIFI, verify the connection to Jetson by using ping on this IP address.\n\n\n\nThe Jetson device must be flashed with JetPack, which includes the Jetson Linux OS and necessary GPU computing libraries such as CUDA and cuDNN. Follow the official NVIDIA JetPack installation guide for instructions. Ensure that firmware version is updated to 36+ for JetPack &gt; 6.\nTo flash Jetson Orin Nano, install NVIDIA SDK Manager on a Linux host machine and follow the setup steps. During flashing, select Jetson SDK Components to install CUDA toolkit in the second step. If CUDA is missing post-installation, follow the JetPack package management guide.\nCUDA installation can be verified with:\n$ nvcc --version\nor\n$ nvidia-smi\nFor additional verification, compile and run a CUDA sample:\n# Clone suitable version for testing CUDA 12.6 \n$ git clone -b v12.5 https://github.com/NVIDIA/cuda-samples.git\n$ cd cuda-samples/Samples/1_Utilities/deviceQuery\n$ make\n$ ./deviceQuery\n\n\n\nJetson devices use integrated GPUs (iGPUs) while default CUDA backend of PyTorch is optimized for discrete GPUs (dGPUs). To enable PyTorch with GPU acceleration on Jetson, follow the custom installation available in NVIDIA instructions and NVIDIA forums. The supporting package torchvision also has to be built from source on the Jetson device.\n\n\nFor PyTorch versions 24.06+ (see Compatibility Matrix), cuSPARSELt is required. Install it with these instructions by selecting Linux OS, aarch64-jetson architecture, and Ubuntu distribution:\n$ wget https://developer.download.nvidia.com/compute/cusparselt/0.7.0/local_installers/cusparselt-local-tegra-repo-ubuntu2204-0.7.0_1.0-1_arm64.deb\n$ sudo dpkg -i cusparselt-local-tegra-repo-ubuntu2204-0.7.0_1.0-1_arm64.deb\n$ sudo cp /var/cusparselt-local-tegra-repo-ubuntu2204-0.7.0/cusparselt-*-keyring.gpg /usr/share/keyrings/\n$ sudo apt-get update\n$ sudo apt-get -y install libcusparselt0 libcusparselt-dev\n\n\n\nCreate a virtual environment (recommended):\n$ sudo apt-get install virtualenv\n$ cd &lt;target-directory&gt;\n$ python3 -m virtualenv -p python3 &lt;venv-name&gt;\n$ source &lt;venv-name&gt;/bin/activate\nInstall PyTorch with a custom wheel built by NVIDIA:\n\nCheck compatibility from NVIDIA Jetson PyTorch matrix.\n\nSelect suitable wheel from list of released wheels by selecting v$JP_VERSION (JetPack version) &gt; pytorch &gt; $PYT_VERSION ... .whl (PyTorch version).\n\nInstall with pip -\n\n$ pip3 install --no-cache https://developer.download.nvidia.com/compute/redist/jp/v$JP_VERSION/pytorch/$PYT_VERSION ... .whl\nIn this tutorial, PyTorch version 2.5 for JetPack 6.1 (still compatible with 6.2) will be installed with:\n$ pip3 install --no-cache https://developer.download.nvidia.com/compute/redist/jp/v61/pytorch/torch-2.5.0a0+872d972e41.nv24.08.17622132-cp310-cp310-linux_aarch64.whl\nVerify with Python Terminal:\n$ python3\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt; print(torch.__version__)\n&gt;&gt;&gt; print('CUDA available: ' + str(torch.cuda.is_available()))\n&gt;&gt;&gt; print('cuDNN version: ' + str(torch.backends.cudnn.version()))\n&gt;&gt;&gt; a = torch.cuda.FloatTensor(2).zero_()\n&gt;&gt;&gt; print('Tensor a = ' + str(a))\n&gt;&gt;&gt; b = torch.randn(2).cuda()\n&gt;&gt;&gt; print('Tensor b = ' + str(b))\n&gt;&gt;&gt; c = a + b\n&gt;&gt;&gt; print('Tensor c = ' + str(c))\n\n\n\ntorchvision must be built from source:\n$ sudo apt-get install libjpeg-dev zlib1g-dev libpython3-dev libopenblas-dev libavcodec-dev libavformat-dev libswscale-dev\n$ git clone --branch release/0.$VERSION https://github.com/pytorch/vision torchvision\n$ cd torchvision\n$ export BUILD_VERSION=0.$VERSION.0\n$ python3 setup.py install --user # remove --user if installing in virtualenv\nIn this tutorial, torchvision version 0.20.0 is installed by replacing $VERSION with 20.\nVerify with Python terminal:\n$ python3\n&gt;&gt;&gt; import torchvision\n&gt;&gt;&gt; print(torchvision.__version__)\n\n\n\nHere are some known issues and tips for troubleshooting:\n\nIf a warning about numpy version is show, downgrade to numpy with pip install 'numpy&lt;2'\n\nIf you encounter this runtime error - RuntimeError: operator torchvision::nms does not exist, follow the instructions in this NVIDIA forum post. Specifically, install the pre-compiled binaries of torch and torchvision:\n\n$ pip install http://jetson.webredirect.org/jp6/cu126/+f/5cf/9ed17e35cb752/torch-2.5.0-cp310-cp310-linux_aarch64.whl#sha256=5cf9ed17e35cb7523812aeda9e7d6353c437048c5a6df1dc6617650333049092\n$ pip install http://jetson.webredirect.org/jp6/cu126/+f/5f9/67f920de3953f/torchvision-0.20.0-cp310-cp310-linux_aarch64.whl#sha256=5f967f920de3953f2a39d95154b1feffd5ccc06b4589e51540dc070021a9adb9\n\n\n\n\nEnsure PyTorch and torchvision were installed first to avoid version conflicts, note that fastai version 2.7.18 requires torch &lt; 2.6. Install fastai and dependencies:\n$ pip install spacy==3.7.2\n$ pip install fastai\nTroubleshooting: spacy version 3.7.2 should be installed first because building wheel for spacy version 3.8.3 can fail on this architecture.\n\n\n\nTo use a remote server running from a Jetson device, first check IP address of Jetson device with Linux command:\n$ ip a\nLook for an IP address similar to 192.168.x.x or 10.x.x.x.\n(Optional) Control Jetson terminal via SSH. Log in with Jetson username (user of Linux OS running on Jetson) and enter password when prompted.\n$ ssh &lt;jetson-username&gt;@&lt;jetson-ip&gt;\nInstall Jupyterlab or Jupyter Notebook on Jetson terminal (or SSH session):\n$ pip install jupyterlab\n$ pip isntall notebook\nStart server from Jetson terminal (or SSH session):\n$ jupyter notebook --no-browser --port=8888 --ip=0.0.0.0\nFrom your local PC, forward port 8888 using SSH:\nssh -N -L 8888:localhost:8888 &lt;jetson-username&gt;@&lt;jetson-ip&gt;\nAnd access running Jupyter server with localhost: http://localhost:8888/",
    "crumbs": [
      "ResNet18 with `fastai` on NVIDIA Jetson"
    ]
  },
  {
    "objectID": "fastai.html#installation",
    "href": "fastai.html#installation",
    "title": "ResNet18 with fastai on NVIDIA Jetson",
    "section": "",
    "text": "This guide provides step-by-step instructions for setting up an NVIDIA® Jetson Orin Nano™ Developer Kit for deep learning with PyTorch, torchvision, and fastai. The setup will be performed via a terminal from a host machine connected via USB or serial connection.\n\n\n\nJetPack - 6.2 (also compatible with 6.1)\n\nCUDA - 12.6\n\nPython - 3.10\n\ncuSPARSELt - 0.7.0\n\ntorch - 2.5.0a0+872d972e41 (NVIDIA wheel).\n\ntorchvision - 0.20.0 (built from source)\n\nspacy - 3.7.2\n\nfastai - 2.7.18\n\n\n\n\nIf your Jetson device is controlled via serial connection, here are some instructions to connect to Wifi using nmcli:\n\nCheck available WiFi networks: nmcli device wifi list\n\nConnect to a WiFi network: nmcli device wifi connect \"SSID_NAME\" password \"YOUR_PASSWORD\"\n\nVerify the Connection: nmcli connection show --active\n\nNote: If encountering unauthorized error, add sudo before these commands.\nAfter connecting to WIFI, the user can retrieve the IP address assigned to the Jetson device. Check the active connections with the command in step 3, which should output their names, UUIDs, types, and devices. Notice the device of the WIFI (type) connection and use it with the command ip a show &lt;DEVICE_NAME&gt;. From another device, e.g., host machine, that also connects to this WIFI, verify the connection to Jetson by using ping on this IP address.\n\n\n\nThe Jetson device must be flashed with JetPack, which includes the Jetson Linux OS and necessary GPU computing libraries such as CUDA and cuDNN. Follow the official NVIDIA JetPack installation guide for instructions. Ensure that firmware version is updated to 36+ for JetPack &gt; 6.\nTo flash Jetson Orin Nano, install NVIDIA SDK Manager on a Linux host machine and follow the setup steps. During flashing, select Jetson SDK Components to install CUDA toolkit in the second step. If CUDA is missing post-installation, follow the JetPack package management guide.\nCUDA installation can be verified with:\n$ nvcc --version\nor\n$ nvidia-smi\nFor additional verification, compile and run a CUDA sample:\n# Clone suitable version for testing CUDA 12.6 \n$ git clone -b v12.5 https://github.com/NVIDIA/cuda-samples.git\n$ cd cuda-samples/Samples/1_Utilities/deviceQuery\n$ make\n$ ./deviceQuery\n\n\n\nJetson devices use integrated GPUs (iGPUs) while default CUDA backend of PyTorch is optimized for discrete GPUs (dGPUs). To enable PyTorch with GPU acceleration on Jetson, follow the custom installation available in NVIDIA instructions and NVIDIA forums. The supporting package torchvision also has to be built from source on the Jetson device.\n\n\nFor PyTorch versions 24.06+ (see Compatibility Matrix), cuSPARSELt is required. Install it with these instructions by selecting Linux OS, aarch64-jetson architecture, and Ubuntu distribution:\n$ wget https://developer.download.nvidia.com/compute/cusparselt/0.7.0/local_installers/cusparselt-local-tegra-repo-ubuntu2204-0.7.0_1.0-1_arm64.deb\n$ sudo dpkg -i cusparselt-local-tegra-repo-ubuntu2204-0.7.0_1.0-1_arm64.deb\n$ sudo cp /var/cusparselt-local-tegra-repo-ubuntu2204-0.7.0/cusparselt-*-keyring.gpg /usr/share/keyrings/\n$ sudo apt-get update\n$ sudo apt-get -y install libcusparselt0 libcusparselt-dev\n\n\n\nCreate a virtual environment (recommended):\n$ sudo apt-get install virtualenv\n$ cd &lt;target-directory&gt;\n$ python3 -m virtualenv -p python3 &lt;venv-name&gt;\n$ source &lt;venv-name&gt;/bin/activate\nInstall PyTorch with a custom wheel built by NVIDIA:\n\nCheck compatibility from NVIDIA Jetson PyTorch matrix.\n\nSelect suitable wheel from list of released wheels by selecting v$JP_VERSION (JetPack version) &gt; pytorch &gt; $PYT_VERSION ... .whl (PyTorch version).\n\nInstall with pip -\n\n$ pip3 install --no-cache https://developer.download.nvidia.com/compute/redist/jp/v$JP_VERSION/pytorch/$PYT_VERSION ... .whl\nIn this tutorial, PyTorch version 2.5 for JetPack 6.1 (still compatible with 6.2) will be installed with:\n$ pip3 install --no-cache https://developer.download.nvidia.com/compute/redist/jp/v61/pytorch/torch-2.5.0a0+872d972e41.nv24.08.17622132-cp310-cp310-linux_aarch64.whl\nVerify with Python Terminal:\n$ python3\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt; print(torch.__version__)\n&gt;&gt;&gt; print('CUDA available: ' + str(torch.cuda.is_available()))\n&gt;&gt;&gt; print('cuDNN version: ' + str(torch.backends.cudnn.version()))\n&gt;&gt;&gt; a = torch.cuda.FloatTensor(2).zero_()\n&gt;&gt;&gt; print('Tensor a = ' + str(a))\n&gt;&gt;&gt; b = torch.randn(2).cuda()\n&gt;&gt;&gt; print('Tensor b = ' + str(b))\n&gt;&gt;&gt; c = a + b\n&gt;&gt;&gt; print('Tensor c = ' + str(c))\n\n\n\ntorchvision must be built from source:\n$ sudo apt-get install libjpeg-dev zlib1g-dev libpython3-dev libopenblas-dev libavcodec-dev libavformat-dev libswscale-dev\n$ git clone --branch release/0.$VERSION https://github.com/pytorch/vision torchvision\n$ cd torchvision\n$ export BUILD_VERSION=0.$VERSION.0\n$ python3 setup.py install --user # remove --user if installing in virtualenv\nIn this tutorial, torchvision version 0.20.0 is installed by replacing $VERSION with 20.\nVerify with Python terminal:\n$ python3\n&gt;&gt;&gt; import torchvision\n&gt;&gt;&gt; print(torchvision.__version__)\n\n\n\nHere are some known issues and tips for troubleshooting:\n\nIf a warning about numpy version is show, downgrade to numpy with pip install 'numpy&lt;2'\n\nIf you encounter this runtime error - RuntimeError: operator torchvision::nms does not exist, follow the instructions in this NVIDIA forum post. Specifically, install the pre-compiled binaries of torch and torchvision:\n\n$ pip install http://jetson.webredirect.org/jp6/cu126/+f/5cf/9ed17e35cb752/torch-2.5.0-cp310-cp310-linux_aarch64.whl#sha256=5cf9ed17e35cb7523812aeda9e7d6353c437048c5a6df1dc6617650333049092\n$ pip install http://jetson.webredirect.org/jp6/cu126/+f/5f9/67f920de3953f/torchvision-0.20.0-cp310-cp310-linux_aarch64.whl#sha256=5f967f920de3953f2a39d95154b1feffd5ccc06b4589e51540dc070021a9adb9\n\n\n\n\nEnsure PyTorch and torchvision were installed first to avoid version conflicts, note that fastai version 2.7.18 requires torch &lt; 2.6. Install fastai and dependencies:\n$ pip install spacy==3.7.2\n$ pip install fastai\nTroubleshooting: spacy version 3.7.2 should be installed first because building wheel for spacy version 3.8.3 can fail on this architecture.\n\n\n\nTo use a remote server running from a Jetson device, first check IP address of Jetson device with Linux command:\n$ ip a\nLook for an IP address similar to 192.168.x.x or 10.x.x.x.\n(Optional) Control Jetson terminal via SSH. Log in with Jetson username (user of Linux OS running on Jetson) and enter password when prompted.\n$ ssh &lt;jetson-username&gt;@&lt;jetson-ip&gt;\nInstall Jupyterlab or Jupyter Notebook on Jetson terminal (or SSH session):\n$ pip install jupyterlab\n$ pip isntall notebook\nStart server from Jetson terminal (or SSH session):\n$ jupyter notebook --no-browser --port=8888 --ip=0.0.0.0\nFrom your local PC, forward port 8888 using SSH:\nssh -N -L 8888:localhost:8888 &lt;jetson-username&gt;@&lt;jetson-ip&gt;\nAnd access running Jupyter server with localhost: http://localhost:8888/",
    "crumbs": [
      "ResNet18 with `fastai` on NVIDIA Jetson"
    ]
  },
  {
    "objectID": "fastai.html#resnet18-on-imagenette-dataset",
    "href": "fastai.html#resnet18-on-imagenette-dataset",
    "title": "ResNet18 with fastai on NVIDIA Jetson",
    "section": "ResNet18 on Imagenette dataset",
    "text": "ResNet18 on Imagenette dataset\nNow that your environment is ready, let’s train a ResNet18 model on Imagenette-320, a smaller dataset derived from ImageNet, but with 320x320 resolution images.\nIn a Python script or Jupyter Notebook, import the necessary fastai libraries:\n\nfrom fastai.vision.all import *\n\nThe Imagenette-320 dataset can be downloaded easily using untar_data() function. This dataset contains separate training and validation sets:\n\npath = untar_data(URLs.IMAGENETTE_320, data=Path.cwd()/'data')\ntrain_files = get_image_files(path/'train')\nval_files = get_image_files(path/'val')\n\nprint(f\"Training set size: {len(train_files)}\")\nprint(f\"Validation set size: {len(val_files)}\")\n\nTraining set size: 9469\nValidation set size: 3925\n\n\nUse ImageDataLoaders.from_folder() to quickly load images and split them into training and validation sets. Set item_tfms to resize all images to 224×224, ensuring compatibility with ResNet models, and batch_tfms to apply ImageNet normalization for consistency with the pretrained ResNet input distribution.\n\ndls = ImageDataLoaders.from_folder(\n    path, \n    valid='val',  # Use 'val' folder for validation set\n    item_tfms=Resize(224),  # Resize images to 224x224\n    batch_tfms=Normalize.from_stats(*imagenet_stats),  # Normalize using ImageNet stats\n)\ndls.show_batch()\n\n\n\n\n\n\n\n\nCreate a ResNet18 model using vision_learner(), which sets up the architecture for image classification. Use accuracy as the main metrics and load a pretrained model. Enable transfer learning with fine_tune(epochs) to adapt to the current dataset.\n\nlearn = vision_learner(dls, resnet18, metrics=accuracy, pretrained=True)\nlearn.fine_tune(1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.246164\n0.051711\n0.985732\n01:03\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.092586\n0.058606\n0.982930\n01:13\n\n\n\n\n\n\nlearn.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfastai also provides the Interpretation class to further analyze model performance by extracting its predictions and identify misclassified images. For instance, the function plot_top_losses() of this class can help visualize the most significant errors.\n\ninterp = Interpretation.from_learner(learn)\ninterp.plot_top_losses(9, figsize=(15,10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe model then can be used to make predictions for new images:\n\nprint(train_files[0])  # Image label is the name of its parent folder\nImage.open(train_files[0])\n\n/home/jetson/jetson-examples/fastai/data/imagenette2-320/train/n03888257/n03888257_457.JPEG\n\n\n\n\n\n\n\n\n\n\npred, pred_idx, probs = learn.predict(train_files[0])  # Predict the label of the first image in the training set\nprint(f'Prediction: {pred}, Probability: {probs[pred_idx]:.4f}')\n\n\n\n\n\n\n\n\nPrediction: n03888257, Probability: 1.0000\n\n\nThe model can also be saved with:\n\nlearn.path = Path.cwd() / 'models' # Save model in 'models' folder\nlearn.export('resnet18.pkl')\n\nTo reload the model in another session:\n\nlearn = load_learner(Path.cwd() / 'models' / 'resnet18.pkl')",
    "crumbs": [
      "ResNet18 with `fastai` on NVIDIA Jetson"
    ]
  }
]